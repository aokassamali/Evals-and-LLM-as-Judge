model,run_path,metrics_path,n_errors_in_run,label_n,label_accuracy,label_macro_f1,evidence_n,evidence_precision,evidence_recall,evidence_f1,avg_predicted_sentences,pct_empty_when_pred_non_nei,pct_nonempty_when_pred_nei,pct_cite_all_unnecessary,pct_pred_shotgun,correct_label_wrong_evidence
deepseek-r1_8b_t0.0,runs\scifact_dev200_deepseek-r1_8b_t0.0.jsonl,results\metrics_json\deepseek-r1_8b_t0.0.json,2,198,0.4797979797979798,0.38944013038059627,198,0.5684769775678868,0.7790404040404041,0.5974226390893058,1.6464646464646464,0.0,0.42771084337349397,0.010101010101010102,0.15151515151515152,1
gemma3_4b_t0.0,runs\scifact_dev200_gemma3_4b_t0.0.jsonl,results\metrics_json\gemma3_4b_t0.0.json,0,200,0.47,0.3883486572126123,200,0.396627344877345,0.8713333333333334,0.4239677544677547,2.655,0.0,0.7352941176470589,0.02,0.235,5
gpt-5.2_t0.0,runs\scifact_dev200_gpt-5.2_t0.0.jsonl,results\metrics_json\gpt-5.2_t0.0.json,0,200,0.78,0.779911912369904,200,0.7332500000000002,0.8761666666666668,0.7414523809523809,1.27,0.0,0.3137254901960784,0.0,0.035,3
llama3.1_8b_t0.0,runs\scifact_dev200_llama3.1_8b_t0.0.jsonl,results\metrics_json\llama3.1_8b_t0.0.json,0,200,0.45,0.40878856593142304,200,0.33012932900432906,0.778,0.3309711122211121,2.835,0.0,0.8,0.075,0.22,15
qwen3_8b_t0.0,runs\scifact_dev200_qwen3_8b_t0.0.jsonl,results\metrics_json\qwen3_8b_t0.0.json,0,200,0.69,0.6557991286296233,200,0.649,0.8661666666666669,0.6643333333333333,1.62,0.0,0.42592592592592593,0.01,0.1,2
