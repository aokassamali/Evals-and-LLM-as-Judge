{
  "deepseek-r1_8b_t0.0": {
    "SUPPORTS": {
      "precision": 0.8695652173913043,
      "recall": 0.2777777777777778,
      "f1": 0.42105263157894735,
      "support": 72
    },
    "REFUTES": {
      "precision": 0.5555555555555556,
      "recall": 0.09615384615384616,
      "f1": 0.16393442622950818,
      "support": 52
    },
    "NEI": {
      "precision": 0.42168674698795183,
      "recall": 0.9459459459459459,
      "f1": 0.5833333333333334,
      "support": 74
    }
  },
  "gemma3_4b_t0.0": {
    "SUPPORTS": {
      "precision": 0.42948717948717946,
      "recall": 0.9054054054054054,
      "f1": 0.5826086956521739,
      "support": 74
    },
    "REFUTES": {
      "precision": 0.6,
      "recall": 0.11538461538461539,
      "f1": 0.1935483870967742,
      "support": 52
    },
    "NEI": {
      "precision": 0.6176470588235294,
      "recall": 0.28378378378378377,
      "f1": 0.3888888888888889,
      "support": 74
    }
  },
  "gpt-5.2_t0.0": {
    "SUPPORTS": {
      "precision": 0.8867924528301887,
      "recall": 0.6351351351351351,
      "f1": 0.7401574803149606,
      "support": 74
    },
    "REFUTES": {
      "precision": 0.8666666666666667,
      "recall": 0.75,
      "f1": 0.8041237113402062,
      "support": 52
    },
    "NEI": {
      "precision": 0.6862745098039216,
      "recall": 0.9459459459459459,
      "f1": 0.7954545454545454,
      "support": 74
    }
  },
  "llama3.1_8b_t0.0": {
    "SUPPORTS": {
      "precision": 0.4672131147540984,
      "recall": 0.7702702702702703,
      "f1": 0.5816326530612245,
      "support": 74
    },
    "REFUTES": {
      "precision": 0.3584905660377358,
      "recall": 0.36538461538461536,
      "f1": 0.3619047619047619,
      "support": 52
    },
    "NEI": {
      "precision": 0.56,
      "recall": 0.1891891891891892,
      "f1": 0.2828282828282828,
      "support": 74
    }
  },
  "qwen3_8b_t0.0": {
    "SUPPORTS": {
      "precision": 0.7777777777777778,
      "recall": 0.6621621621621622,
      "f1": 0.7153284671532847,
      "support": 74
    },
    "REFUTES": {
      "precision": 0.6896551724137931,
      "recall": 0.38461538461538464,
      "f1": 0.49382716049382713,
      "support": 52
    },
    "NEI": {
      "precision": 0.6388888888888888,
      "recall": 0.9324324324324325,
      "f1": 0.7582417582417582,
      "support": 74
    }
  }
}